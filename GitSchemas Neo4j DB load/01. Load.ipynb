{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download permissively licensed GitScehmas dataset and transform froma diuctionary to an array to facilitate loading into Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to data/gitSchemasPermissiveDataset.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    " \n",
    "def fetch_gitScehmas():\n",
    "    # This is likely a time limited URL, preview link to follow and get download link from here: https://drive.google.com/file/d/1HwxeMQ7dym5md5igG2EBV0oPPR5Y0dAn/view?usp=sharing\n",
    "    gitSchemasPermissiveDataset = 'https://drive.google.com/u/0/uc?id=1HwxeMQ7dym5md5igG2EBV0oPPR5Y0dAn&export=download'\n",
    "\n",
    "    output_file = 'data/gitSchemasPermissiveDataset.json'\n",
    "    transformed_file = 'data/gitSchemasPermissiveDataset_transformed.json'\n",
    "\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(gitSchemasPermissiveDataset)\n",
    "\n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Access the content as text\n",
    "            data = response.text\n",
    "\n",
    "            # Write the data to a file\n",
    "            with open(output_file, 'w', encoding='utf-8') as file:\n",
    "                file.write(data)\n",
    "\n",
    "            print(f\"Data successfully written to {output_file}\")\n",
    "        else:\n",
    "            print(f\"Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request exception: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    \n",
    "    with open(output_file, 'r', encoding='utf-8') as in_file:\n",
    "        dict = json.load(in_file)\n",
    "        array = [{'key': k, 'value': dict[k]} for k in dict]\n",
    "        with open(transformed_file, 'w') as out_file:\n",
    "            json.dump(array, out_file)\n",
    "\n",
    "fetch_gitScehmas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load into Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DELETE?\n",
    "# import pandas as pd\n",
    "\n",
    "# # File path to your CSV file\n",
    "\n",
    "\n",
    "# # Read the CSV file into a DataFrame using pandas\n",
    "# detected_keys = pd.read_csv('./data/test/detected_keys.csv')\n",
    "\n",
    "# testSchemas = []\n",
    "\n",
    "# for index, row in detected_keys.iterrows():\n",
    "#     testSchemas.append(row['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neo4j database!\n",
      "Connection to Neo4j closed.\n"
     ]
    }
   ],
   "source": [
    "# Move tansformed file to import directory of your neo4j instance before running the below\n",
    "# Ensure that apoc.import.file.enabled=true us set in your apoc.conf\n",
    "from Neo4jDriver import Neo4jDriver\n",
    "\n",
    "\n",
    "with Neo4jDriver() as neo4j:\n",
    "\n",
    "    # Create necessary schema\n",
    "    createSchemas = [\"CREATE CONSTRAINT IF NOT EXISTS FOR (s:Schema) REQUIRE (s.url) IS UNIQUE;\", \n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (t:Table) REQUIRE (t.name, t.schemaId) IS UNIQUE;\", \n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (c:Column) REQUIRE (c.name, c.table, c.type, c.schemaId) IS UNIQUE;\", \n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (p:PrimaryKey) REQUIRE (p.table, p.schemaId) IS UNIQUE;\", \n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (f:ForeignKey) REQUIRE (f.table, f.schemaId, f.fkName) IS UNIQUE;\"]\n",
    "    \n",
    "    for q in createSchemas:\n",
    "        neo4j.execute_write_query(q)\n",
    "\n",
    "\n",
    "    # Load from json file\n",
    "    file = '///gitSchemasPermissiveDataset_transformed.json'\n",
    "\n",
    "    returning_statement = f\"\"\"\n",
    "        CALL apoc.load.json('{file}')\n",
    "        YIELD value AS schema\n",
    "        RETURN schema\n",
    "        \"\"\"\n",
    "    # WHERE schema.INFO.url IN $testSchemas\n",
    "    per_item_statement = \"\"\"\n",
    "        // Create Schema\n",
    "        WITH schema\n",
    "        WITH schema.value.INFO.url AS key, schema.value AS schema\n",
    "        MERGE (schemaNode:Schema { url: key })\n",
    "        SET schemaNode+= schema.INFO\n",
    "        WITH schemaNode, schema\n",
    "        // Create associated Tables\n",
    "        WITH keys(schema.TABLES) AS tableKeys, schemaNode, schema\n",
    "        UNWIND tableKeys AS tableKey\n",
    "        MERGE (tableNode:Table { name: tableKey, schemaId: schemaNode.url })<-[:CONTAINS_TABLE]-(schemaNode)\n",
    "        // Create linked Columns\n",
    "        WITH schema.TABLES[tableKey] AS table, tableNode, schemaNode, tableKey\n",
    "        WITH tableNode, table, table.COLUMNS AS columns, schemaNode, tableKey\n",
    "        UNWIND columns AS column\n",
    "        MERGE (columnNode:Column { name: column[0], table: tableKey, type: column[1], schemaId:schemaNode.url })<-[:HAS_COLUMN]-(tableNode)\n",
    "        // Create Primary Keys\n",
    "        WITH tableNode, table, table.PRIMARY_KEYS AS primaryKeys, schemaNode\n",
    "        UNWIND primaryKeys AS primaryKey\n",
    "        MATCH (tableNode)-[:HAS_COLUMN]-(pkc:Column { name: primaryKey })\n",
    "        MERGE (pk:PrimaryKey { table:tableNode.name, schemaId:schemaNode.url })\n",
    "        MERGE (pkc)<-[:PK_COLUMN]-(pk)\n",
    "        // Create Foreign Keys\n",
    "        WITH tableNode, table.FOREIGN_KEYS AS foreignKeys, schemaNode\n",
    "        UNWIND foreignKeys AS foreignKey\n",
    "        UNWIND foreignKey.FOREIGN_KEY AS fk_component\n",
    "        MATCH (tableNode)-[:HAS_COLUMN]-(fkc:Column { name: fk_component })\n",
    "        MERGE (fk:ForeignKey { table:tableNode.name, schemaId:schemaNode.url, fkName:foreignKey.FOREIGN_KEY })\n",
    "        MERGE (fkc)<-[:FK_COLUMN]-(fk)\n",
    "        WITH foreignKey, schemaNode, tableNode, fk\n",
    "        UNWIND foreignKey.REFERENCE_COLUMN AS fk_reference_column\n",
    "        MATCH (schemaNode)-[:CONTAINS_TABLE]->(:Table { name: foreignKey.REFERENCE_TABLE })-[:HAS_COLUMN]->(fkrc:Column {name: fk_reference_column})\n",
    "        MERGE (fkrc)<-[:FK_REFERENCE_COLUMN]-(fk)\n",
    "        \"\"\"\n",
    "    \n",
    "    options = \"{ batchSize:5, parallel: true}\" #, params: {testSchemas: \" + str(testSchemas) + \"} \n",
    "\n",
    "\n",
    "\n",
    "    load_query = f\"\"\"\n",
    "        CALL apoc.periodic.iterate(\"{returning_statement}\",\"{per_item_statement}\",{options})\n",
    "    \"\"\"\n",
    "\n",
    "    neo4j.execute_write_query(load_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
